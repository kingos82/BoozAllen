{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\anaconda3\\envs\\boz_allen\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import utils\n",
    "from utils import rename_col, add_rul, minmax_dic, minmax_scl,smooth, smoothing, drop_org, LSTMRegressor, n_hidden_units, test, test_model, device\n",
    "import torch\n",
    "import pickle\n",
    "import joblib\n",
    "import sys, os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import plotly.graph_objects as go\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "sys.path.append(os.path.abspath(os.path.join(\"..\")))\n",
    "sys.path.append(os.path.abspath(os.path.join('..','./CMAPSSData/')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print all paths available\n",
    "data_folder = [item for item in sys.path if 'CMAPSSData' in item]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['d:\\\\Documents-folders\\\\GitHub\\\\BoozAllen']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "root_folder = [item for item in sys.path if 'BoozAllen' in item and 'CMAPSSData' not in item and 'scripts' not in item]\n",
    "root_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_model(input):\n",
    "    if input ==\"model1\":\n",
    "        model_path=\"./model2140_1.pt\"\n",
    "        train_path=\"./CMAPSSData/train_FD001.txt\"\n",
    "    elif input=='model2':\n",
    "        model_path=\"./model2140_2.pt\"\n",
    "        train_path=\"./CMAPSSData/train_FD002.txt\"\n",
    "    elif input=='model3':\n",
    "        model_path=\"./model2140_3.pt\"\n",
    "        train_path=\"./CMAPSSData/train_FD003.txt\"\n",
    "    elif input=='model4':\n",
    "        model_path=\"./model2140_4.pt\"\n",
    "        train_path=\"./CMAPSSData/train_FD004.txt\"\n",
    "    return model_path, train_path\n",
    "\n",
    "\n",
    "\n",
    "def choose_test(input):\n",
    "    if input ==\"test1\":\n",
    "        test_path=\"./CMAPSSData/test_FD001.txt\"\n",
    "        RLU_path=\"./CMAPSSData/RUL_FD001.txt\"\n",
    "    elif input=='test2':\n",
    "        test_path=\"./CMAPSSData/test_FD002.txt\"\n",
    "        RLU_path=\"./CMAPSSData/RUL_FD002.txt\"\n",
    "    elif input=='test3':\n",
    "        test_path=\"./CMAPSSData/test_FD003.txt\"\n",
    "        RLU_path=\"./CMAPSSData/RUL_FD003.txt\"\n",
    "    elif input=='test4':\n",
    "        test_path=\"./CMAPSSData/test_FD004.txt\"\n",
    "        RLU_path=\"./CMAPSSData/RUL_FD004.txt\"\n",
    "    return test_path, RLU_path\n",
    "\n",
    "def plt_rlu(y, y_pred):\n",
    "    fig = go.Figure()\n",
    "\n",
    "    fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x =np.arange(len(y_pred)),\n",
    "        y = y_pred,\n",
    "        mode = 'lines', # Change the mode in this section!\n",
    "        name='prediction'\n",
    "        )\n",
    "    )\n",
    "\n",
    "    fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x =np.arange(len(y)),\n",
    "        y = y,\n",
    "        mode = 'lines', # Change the mode in this section!\n",
    "        name='True'\n",
    "        )\n",
    "    )\n",
    "    return fig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wrangle_data(input_path): \n",
    "\n",
    "        \n",
    "    df = pd.read_csv(Path(input_path), header=None, sep = ' ')\n",
    "    \n",
    "    ## Refactor data wrangling commands\n",
    "    df=rename_col(df)\n",
    "    df=add_rul(df, 'train')\n",
    "\n",
    "    #Drop os3, s1, s5, s6, s10, s16, s18, s19 from both train and test\n",
    "    drop_cols1 = ['os3','s1','s5','s6','s10','s16','s18','s19']\n",
    "    df = df.drop(drop_cols1, axis = 1)\n",
    "\n",
    "    #minmax scale the sensor values\n",
    "    minmax_dict=minmax_dic(df)\n",
    "    df=minmax_scl(df, minmax_dict)\n",
    "\n",
    "    #smoothing the training & test data\n",
    "    df=smoothing(df)\n",
    "\n",
    "    #drop original data\n",
    "    df=drop_org(df)\n",
    "\n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_y_true_and_pred(df, model_input, test_input):\n",
    "\n",
    "    model_path, train_path = choose_model(model_input)\n",
    "    test_path, RUL_path = choose_test(test_input)\n",
    "\n",
    "    df_train = wrangle_data(train_path)\n",
    "    df_test = wrangle_data(test_path)\n",
    "\n",
    "    # Instantiate the model\n",
    "    n_features = len([c for c in df_train.columns if 's' in c])\n",
    "    loaded_model = LSTMRegressor(n_features, n_hidden_units)\n",
    "\n",
    "    # Load the saved state_dict\n",
    "    full_model_path = Path(model_path) \n",
    "    loaded_model.load_state_dict(torch.load(full_model_path))\n",
    "\n",
    "    eng_num=df_test['unit'].max()+1\n",
    "    units = np.arange(1,eng_num)\n",
    "\n",
    "    test_data = test(units, df_test)\n",
    "\n",
    "    torch.manual_seed(5)\n",
    "\n",
    "    testloader = DataLoader(test_data, batch_size = 100)\n",
    "    mse, l1, y_pred, y = test_model(loaded_model, testloader, device)\n",
    "\n",
    "    df_RUL = pd.read_csv(Path(RUL_path), header=None, sep = ' ')\n",
    "    y=df_RUL[0].to_list()\n",
    "\n",
    "    return y, y_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import rename_col, add_rul, minmax_dic, minmax_scl,smooth, smoothing, drop_org, LSTMRegressor, n_hidden_units, test, test_model, device\n",
    "import torch\n",
    "\n",
    "df_test = pd.read_csv(Path(data_folder[0],\"test_FD001.txt\"), header=None, sep = ' ')\n",
    "df_train = pd.read_csv(Path(data_folder[0],\"train_FD001.txt\"), header=None, sep = ' ')\n",
    "\n",
    "## Refactor data wrangling commands\n",
    "df_train=rename_col(df_train)\n",
    "df_test=rename_col(df_test)\n",
    "\n",
    "df_train=add_rul(df_train, 'train')\n",
    "df_test=add_rul(df_test, 'test')\n",
    "\n",
    "\n",
    "#Drop os3, s1, s5, s6, s10, s16, s18, s19 from both train and test\n",
    "\n",
    "drop_cols1 = ['os3','s1','s5','s6','s10','s16','s18','s19']\n",
    "df_train = df_train.drop(drop_cols1, axis = 1)\n",
    "df_test = df_test.drop(drop_cols1, axis = 1)\n",
    "\n",
    "#minmax scale the sensor values\n",
    "minmax_dict=minmax_dic(df_train)\n",
    "df_train=minmax_scl(df_train, minmax_dict)\n",
    "df_test=minmax_scl(df_test, minmax_dict)\n",
    "\n",
    "#smoothing the training & test data\n",
    "df_train=smoothing(df_train)\n",
    "df_test=smoothing(df_test)\n",
    "\n",
    "#drop original data\n",
    "df_train=drop_org(df_train)\n",
    "df_test=drop_org(df_test)\n",
    "\n",
    "# Instantiate the model\n",
    "n_features = len([c for c in df_train.columns if 's' in c])\n",
    "loaded_model = LSTMRegressor(n_features, n_hidden_units)\n",
    "\n",
    "# Load the saved state_dict\n",
    "model_path = Path(root_folder[0], \"model2140_1.pt\") \n",
    "loaded_model.load_state_dict(torch.load(model_path))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Preparing Training, Validation and Test Dataloaders\n",
    "\n",
    "eng_num=df_test['unit'].max()+1\n",
    "units = np.arange(1,eng_num)\n",
    "\n",
    "test_data = test(units, df_test)\n",
    "\n",
    "torch.manual_seed(5)\n",
    "\n",
    "testloader = DataLoader(test_data, batch_size = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mse, l1, y_pred, y = test_model(loaded_model, testloader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_RUL = pd.read_csv(Path(data_folder[0], 'RUL_FD001.txt'), header=None, sep = ' ')\n",
    "y=df_RUL[0].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt_rlu(y, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
