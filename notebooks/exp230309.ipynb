{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import sys, os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "sys.path.append(os.path.abspath(os.path.join(\"..\")))\n",
    "sys.path.append(os.path.abspath(os.path.join('.','./CMAPSSData/')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rename_col(df):\n",
    "    '''\n",
    "    this function creates new columns and assigns them to an exisiting data frame\n",
    "    Let's attach column names: 3 operational setting columns (os + number), and 21 sensor columns (s + number). \n",
    "    Let's drop last 2 columns with NaNs\n",
    "    '''\n",
    "    col_names = []\n",
    "    col_names.append('unit')\n",
    "    col_names.append('time')\n",
    "    for i in range(1,4):\n",
    "        col_names.append('os'+str(i))\n",
    "    for i in range(1,22):\n",
    "        col_names.append('s'+str(i))\n",
    "    df = df.iloc[:,:-2].copy()\n",
    "    df.columns = col_names\n",
    "    return df\n",
    "\n",
    "def add_rul(df, test_or_train):\n",
    "    '''\n",
    "    attaching remaining useful lifetime to the dataset\n",
    "    '''\n",
    "    rul_list = []\n",
    "\n",
    "    df = df.copy()\n",
    "\n",
    "    for n in np.arange(1,101):\n",
    "\n",
    "        time_list = np.array(df[df['unit'] == n]['time'])\n",
    "        length = len(time_list)\n",
    "        if test_or_train=='test':\n",
    "            #print(df.iloc[n-1].tolist()[0], n)\n",
    "            rul_val = df.iloc[n-1].tolist()[0]\n",
    "            rul = list(length - time_list + rul_val)\n",
    "        elif test_or_train=='train':\n",
    "            rul = list(length - time_list)\n",
    "        else:\n",
    "            print('test_or_train must be \"test\" or \"train\"')\n",
    "            return\n",
    "        rul_list += rul\n",
    "\n",
    "    df['rul'] = rul_list\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def minmax_dic(df):\n",
    "    minmax_dict={}\n",
    "    for c in df.columns:\n",
    "        if 's' in c:\n",
    "            minmax_dict[c+'min'] = df[c].min()\n",
    "            minmax_dict[c+'max']=  df[c].max()\n",
    "    return minmax_dict\n",
    "\n",
    "def minmax_scl(df, dict):\n",
    "    '''\n",
    "    minmax scale\n",
    "    '''\n",
    "    df = df.copy()\n",
    "    for c in df.columns:\n",
    "        if 's' in c:\n",
    "            df[c] = (df[c] - dict[c+'min']) / (dict[c+'max'] - dict[c+'min'])\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def smooth(s, b = 0.98):\n",
    "    '''\n",
    "    Smoothing Function: Exponentially Weighted Averages\n",
    "    '''\n",
    "\n",
    "    v = np.zeros(len(s)+1) #v_0 is already 0.\n",
    "    bc = np.zeros(len(s)+1)\n",
    "    for i in range(1, len(v)): #v_t = 0.95\n",
    "        v[i] = (b * v[i-1] + (1-b) * s[i-1]) \n",
    "        bc[i] = 1 - b**i\n",
    "\n",
    "    sm = v[1:] / bc[1:]\n",
    "    return sm\n",
    "\n",
    "\n",
    "def smoothing(df):\n",
    "    '''\n",
    "    Smoothing each time series for each engine in both training and test sets\n",
    "    '''\n",
    "    df = df.copy()\n",
    "    for c in df.columns:\n",
    "        sm_list = []\n",
    "        if 's' in c:\n",
    "            for n in np.arange(1,101):\n",
    "                s = np.array(df[df['unit'] == n][c].copy())\n",
    "                sm = list(smooth(s, 0.98))\n",
    "                sm_list += sm\n",
    "            df[c+'_smoothed'] = sm_list\n",
    "    return df\n",
    "\n",
    "def drop_org(df):\n",
    "    '''\n",
    "    drop original column leaving smooth data\n",
    "    '''\n",
    "    df = df.copy()\n",
    "    for c in df.columns:\n",
    "        if ('s' in c) and ('smoothed' not in c):\n",
    "            df[c] = df[c+'_smoothed']\n",
    "            df.drop(c+'_smoothed', axis = 1, inplace = True)\n",
    "    return df\n",
    "    \n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv(\"d:/Documents-folders/GitHub/BoozAllen/CMAPSSData/test_FD001.txt\", header=None, sep = ' ')\n",
    "df_train = pd.read_csv(\"d:/Documents-folders/GitHub/BoozAllen/CMAPSSData/train_FD001.txt\", header=None, sep = ' ')\n",
    "\n",
    "\n",
    "\n",
    "## Refactor data wrangling commands\n",
    "df_train=rename_col(df_train)\n",
    "df_test=rename_col(df_test)\n",
    "\n",
    "df_train=add_rul(df_train, 'train')\n",
    "df_test=add_rul(df_test, 'test')\n",
    "\n",
    "\n",
    "#Drop os3, s1, s5, s6, s10, s16, s18, s19 from both train and test\n",
    "\n",
    "drop_cols1 = ['os3','s1','s5','s6','s10','s16','s18','s19']\n",
    "df_train = df_train.drop(drop_cols1, axis = 1)\n",
    "df_test = df_test.drop(drop_cols1, axis = 1)\n",
    "\n",
    "#minmax scale the sensor values\n",
    "minmax_dict=minmax_dic(df_train)\n",
    "df_train=minmax_scl(df_train, minmax_dict)\n",
    "df_test=minmax_scl(df_test, minmax_dict)\n",
    "\n",
    "#smoothing the training & test data\n",
    "df_train=smoothing(df_train)\n",
    "df_test=smoothing(df_test)\n",
    "\n",
    "#drop original data\n",
    "df_train=drop_org(df_train)\n",
    "df_test=drop_org(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "Can't get attribute 'LSTMRegressor' on <module '__main__'>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32md:\\Documents-folders\\GitHub\\BoozAllen\\notebooks\\exp230309.ipynb Cell 4\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/Documents-folders/GitHub/BoozAllen/notebooks/exp230309.ipynb#W5sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m model\u001b[39m=\u001b[39mjoblib\u001b[39m.\u001b[39;49mload(\u001b[39m'\u001b[39;49m\u001b[39md:/Documents-folders/GitHub/BoozAllen/model2140.joblib\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\anaconda3\\envs\\boz_allen\\lib\\site-packages\\joblib\\numpy_pickle.py:658\u001b[0m, in \u001b[0;36mload\u001b[1;34m(filename, mmap_mode)\u001b[0m\n\u001b[0;32m    652\u001b[0m             \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(fobj, \u001b[39mstr\u001b[39m):\n\u001b[0;32m    653\u001b[0m                 \u001b[39m# if the returned file object is a string, this means we\u001b[39;00m\n\u001b[0;32m    654\u001b[0m                 \u001b[39m# try to load a pickle file generated with an version of\u001b[39;00m\n\u001b[0;32m    655\u001b[0m                 \u001b[39m# Joblib so we load it with joblib compatibility function.\u001b[39;00m\n\u001b[0;32m    656\u001b[0m                 \u001b[39mreturn\u001b[39;00m load_compatibility(fobj)\n\u001b[1;32m--> 658\u001b[0m             obj \u001b[39m=\u001b[39m _unpickle(fobj, filename, mmap_mode)\n\u001b[0;32m    659\u001b[0m \u001b[39mreturn\u001b[39;00m obj\n",
      "File \u001b[1;32mc:\\anaconda3\\envs\\boz_allen\\lib\\site-packages\\joblib\\numpy_pickle.py:577\u001b[0m, in \u001b[0;36m_unpickle\u001b[1;34m(fobj, filename, mmap_mode)\u001b[0m\n\u001b[0;32m    575\u001b[0m obj \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    576\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 577\u001b[0m     obj \u001b[39m=\u001b[39m unpickler\u001b[39m.\u001b[39;49mload()\n\u001b[0;32m    578\u001b[0m     \u001b[39mif\u001b[39;00m unpickler\u001b[39m.\u001b[39mcompat_mode:\n\u001b[0;32m    579\u001b[0m         warnings\u001b[39m.\u001b[39mwarn(\u001b[39m\"\u001b[39m\u001b[39mThe file \u001b[39m\u001b[39m'\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m has been generated with a \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    580\u001b[0m                       \u001b[39m\"\u001b[39m\u001b[39mjoblib version less than 0.10. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    581\u001b[0m                       \u001b[39m\"\u001b[39m\u001b[39mPlease regenerate this pickle file.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    582\u001b[0m                       \u001b[39m%\u001b[39m filename,\n\u001b[0;32m    583\u001b[0m                       \u001b[39mDeprecationWarning\u001b[39;00m, stacklevel\u001b[39m=\u001b[39m\u001b[39m3\u001b[39m)\n",
      "File \u001b[1;32mc:\\anaconda3\\envs\\boz_allen\\lib\\pickle.py:1212\u001b[0m, in \u001b[0;36m_Unpickler.load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1210\u001b[0m             \u001b[39mraise\u001b[39;00m \u001b[39mEOFError\u001b[39;00m\n\u001b[0;32m   1211\u001b[0m         \u001b[39massert\u001b[39;00m \u001b[39misinstance\u001b[39m(key, bytes_types)\n\u001b[1;32m-> 1212\u001b[0m         dispatch[key[\u001b[39m0\u001b[39;49m]](\u001b[39mself\u001b[39;49m)\n\u001b[0;32m   1213\u001b[0m \u001b[39mexcept\u001b[39;00m _Stop \u001b[39mas\u001b[39;00m stopinst:\n\u001b[0;32m   1214\u001b[0m     \u001b[39mreturn\u001b[39;00m stopinst\u001b[39m.\u001b[39mvalue\n",
      "File \u001b[1;32mc:\\anaconda3\\envs\\boz_allen\\lib\\pickle.py:1537\u001b[0m, in \u001b[0;36m_Unpickler.load_stack_global\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1535\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mtype\u001b[39m(name) \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mstr\u001b[39m \u001b[39mor\u001b[39;00m \u001b[39mtype\u001b[39m(module) \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mstr\u001b[39m:\n\u001b[0;32m   1536\u001b[0m     \u001b[39mraise\u001b[39;00m UnpicklingError(\u001b[39m\"\u001b[39m\u001b[39mSTACK_GLOBAL requires str\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m-> 1537\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mappend(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfind_class(module, name))\n",
      "File \u001b[1;32mc:\\anaconda3\\envs\\boz_allen\\lib\\pickle.py:1581\u001b[0m, in \u001b[0;36m_Unpickler.find_class\u001b[1;34m(self, module, name)\u001b[0m\n\u001b[0;32m   1579\u001b[0m \u001b[39m__import__\u001b[39m(module, level\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[0;32m   1580\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mproto \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39m4\u001b[39m:\n\u001b[1;32m-> 1581\u001b[0m     \u001b[39mreturn\u001b[39;00m _getattribute(sys\u001b[39m.\u001b[39;49mmodules[module], name)[\u001b[39m0\u001b[39m]\n\u001b[0;32m   1582\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1583\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mgetattr\u001b[39m(sys\u001b[39m.\u001b[39mmodules[module], name)\n",
      "File \u001b[1;32mc:\\anaconda3\\envs\\boz_allen\\lib\\pickle.py:331\u001b[0m, in \u001b[0;36m_getattribute\u001b[1;34m(obj, name)\u001b[0m\n\u001b[0;32m    329\u001b[0m         obj \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(obj, subpath)\n\u001b[0;32m    330\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m:\n\u001b[1;32m--> 331\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mCan\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt get attribute \u001b[39m\u001b[39m{!r}\u001b[39;00m\u001b[39m on \u001b[39m\u001b[39m{!r}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    332\u001b[0m                              \u001b[39m.\u001b[39mformat(name, obj)) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m    333\u001b[0m \u001b[39mreturn\u001b[39;00m obj, parent\n",
      "\u001b[1;31mAttributeError\u001b[0m: Can't get attribute 'LSTMRegressor' on <module '__main__'>"
     ]
    }
   ],
   "source": [
    "model=joblib.load('d:/Documents-folders/GitHub/BoozAllen/model2140.joblib')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = model.predict(df_test.iloc[0:1,2:])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.15 ('boz_allen')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f2d2ceb09a58c56c4752bda16029ac7ed377d3670fcd545878ded9fb754accd2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
